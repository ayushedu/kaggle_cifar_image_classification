{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Image classification using Mahotas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import mahotas as mh\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load images\n",
    "images = glob('data/train/train/*.png')\n",
    "images = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## UNCOMMENT THE BELOW LINES. BELOW LINES ARE FOR IMAGE LOADING AND FEATURE EXTRACTION\n",
    "# features = []\n",
    "\n",
    "# for im in images:\n",
    "#     im = mh.imread(im)\n",
    "#     im = mh.colors.rgb2gray(im, dtype=np.uint8)\n",
    "#     features.append(mh.features.haralick(im).ravel())\n",
    "    \n",
    "# features = np.array(features)\n",
    "# np.save('data/mahotas_features',features)\n",
    "\n",
    "features = np.load('data/mahotas_features.npy') # Image data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'horse': 5, 'automobile': 3, 'deer': 2, 'dog': 8, 'frog': 0, 'cat': 7, 'truck': 1, 'ship': 6, 'bird': 4, 'airplane': 9}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Read labels\"\"\"\n",
    "labels = pd.read_csv('data/trainLabels.csv') # Image labels\n",
    "# get unique labels\n",
    "unique_labels = labels.label.unique().tolist()\n",
    "unique_labels = dict((val, unique_labels.index(val)) for val in unique_labels)\n",
    "print unique_labels\n",
    "\n",
    "# convert labels to int\n",
    "y = [unique_labels[val] for val in labels.label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features, labels, y 50000 50000 50000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print '# features, labels, y', len(features), len(labels), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Instantiate model\"\"\"\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = Pipeline([('preproc', StandardScaler()),('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 9.4%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Train model\"\"\"\n",
    "from sklearn import cross_validation\n",
    "cv = cross_validation.LeaveOneOut(len(images))\n",
    "scores = cross_validation.cross_val_score(clf, features, y[:500], cv=cv)\n",
    "print('Accuracy: {:.1%}'.format(scores.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    7.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=110, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Train logistic regression model\"\"\"\n",
    "logr = LogisticRegression(verbose=1,solver=\"lbfgs\",max_iter=110)\n",
    "logr.fit( features[:40000], y[:40000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# correct predictions 795\n",
      "Percentage correct 9\n"
     ]
    }
   ],
   "source": [
    "results = logr.predict(features[40000:48000])\n",
    "\n",
    "crt = 0\n",
    "for i in range(len(results)):\n",
    "    crt += (results[i] == y[40000+i])\n",
    "    \n",
    "print '# correct predictions', crt\n",
    "print 'Percentage correct', (crt*100/len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Creating my own features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
